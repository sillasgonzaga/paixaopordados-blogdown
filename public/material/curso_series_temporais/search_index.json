[
["index.html", "Curso de Séries Temporais - IBPAD Prefácio Instrutor Instalação de pacotes", " Curso de Séries Temporais - IBPAD © Sillas Teixeira Gonzaga 2019-06-02 Prefácio Este curso é oferecido pelo Instituto Brasileiro de Pesquisa e Análise de Dados, o IBPAD, um centro independente de pesquisa e formação de analistas e pesquisadores nas áreas de Pesquisa e Opinião Pública, Política e Relações Governamentais e Comunicação Digital. IBPAD Instrutor Formado em Engenharia de Produção, possui grande interesse em Ciência de Dados. Usa o R há pelo menos três anos não só profissionalmente, mas também em diversos projetos pessoais, como o blog Paixão por Dados. É autor do pacote de previsões temporais chamado mafs. Instalação de pacotes Para este curso, serão usados alguns pacotes do R. Para poder acompanhar os códigos disponíveis no material, rode o seguinte comando no R: pacotes &lt;- c(&quot;forecast&quot;, &quot;magrittr&quot;, &quot;tidyverse&quot;, &quot;GGally&quot;, &quot;broom&quot;, &quot;ggalt&quot;, &quot;ggExtra&quot;, &quot;BETS&quot;, &quot;lubridate&quot;, &quot;seasonal&quot;, &quot;mafs&quot;, &quot;dygraphs&quot;, &quot;gtrendsR&quot;) install.packages(pacotes) Link para o Google Drive com scripts de exercício: https://gist.github.com/sillasgonzaga/0ddc256e991407b05d7be4d3405fe55e "],
["introducao.html", "Capítulo 1 Introdução a Séries Temporais 1.1 O que são Séries Temporais 1.2 Elementos das Séries Temporais 1.3 Séries temporais no R 1.4 Gráficos interativos com dygraphs", " Capítulo 1 Introdução a Séries Temporais 1.1 O que são Séries Temporais Quando uma variável é medida e registrada sequencialmente em tempo durante ou em um intervalo fixo, chamado de intervalo amostral, os dados resultantes são chamados de série temporal. Observações coletadas em um intervalo amostral no passado recebem o nome de série temporal histórica e são usadas para analisar e entender o passado e para prever o futuro. Em outras palavras, série temporal é uma sequência de dados em ordem cronológica. Exemplos: * Cotação do dólar; * Taxa de desemprego; * Receita de vendas; * Inflação 1.2 Elementos das Séries Temporais Séries temporais possuem três tipos de padrões, também chamados de componentes: Tendência: ocorre quando a variável da série temporal apresenta um aumento ou diminuição a longo prazo; Sazonalidade: corresponde a um padrão fixo que se repete no mesmo período de tempo (Ex.: aumento das vendas de roupa de praia no verão); Ciclos: ocorre quando os dados mostram subidas e quedas que não possuem um período fixo; Erro aleatório: diz respeito aos movimentos irregulares explicados por causas desconhecidas. Alguns exemplos desses componentes são mostrados abaixo: # serie sem sazonalidade ou tendencia plot(rnorm(200, mean = 0, sd = 1), type = &quot;l&quot;, xlab = &quot;Observação&quot;, ylab = &quot;&quot;) # serie com sazonalidade e sem tendencia plot(ldeaths) # serie com tendencia e sem sazonalidade x &lt;- 1:500 set.seed(123) x &lt;- x/50 + rnorm(500) plot(x, type = &quot;l&quot;) # serie com sazonalidade e tendencia data(&quot;AirPassengers&quot;) plot(AirPassengers) # plotando cada elemento separadamente plot(decompose(AirPassengers)) O pacote forecast traz ótimas funções para analisar os componentes de uma determinada série. Alguns exemplos são: library(forecast) ggseasonplot(AirPassengers) ggsubseriesplot(AirPassengers) Outro importante elemento de uma série temporal é a frequência, que é define o intervalo de tempo que separa uma observação (um dado) de outra: diária, semanal, mensal, trimestral, anual, etc. 1.3 Séries temporais no R Na verdade, todo o tidyverse é voltado para objetos do tipo data frame, com exceção do purrr, que foca em listas. Grande parte do universo de séries temporais é feita usando objetos do tipo ts. As funções de modelagem dos pacotes forecast e mafs, por exemplo, aceitam como inputs apenas objetos da classe ts. Portanto, nem sempre o conhecimento em tidyverse resolverá todos os problemas em programação R. Um objeto do tipo ts pode ser criado da seguinte maneira: minha.st &lt;- ts(rnorm(200), start = c(1991, 1), frequency = 12) # o tidyverse não oferece suporte nativo a objetos ts. # contudo, o pacote forecast consegue facilitar o plot de STs em graficos do ggplot2: library(forecast) autoplot(minha.st) 1.4 Gráficos interativos com dygraphs Acha os gráficos do ggplot2 chatos e sem vida? Com o pacote dygraphs é possível criar gráficos com recursos interativos: library(dygraphs) dygraph(AirPassengers) Exercícios: - Instale o pacote BETS - Carregue os pacotes BETS e forecast - Use a função BETSsearch() para pesquisar series temporais de um tema de sua preferencia - Após escolher uma série temporal, baixe-a usando a função BETS.get(). Armazene o resultado na variavel ´ts.exemplo´. - Analise os componentes de tendencia, sazonalidade e ciclo usando as funcões mostradas (plot, ggseasonplot, ggsubseriesplot, ggmonthplot, etc) - Repita o procedimento para o pacote gtrendsBR "],
["regressao.html", "Capítulo 2 Regressão 2.1 Análise exploratória 2.2 Correlação 2.3 Modelagem por regressão simples 2.4 Regressão multivariada 2.5 Regressão como modelo preditivo 2.6 Referências", " Capítulo 2 Regressão library(tidyverse) library(GGally) library(broom) A técnica chamada de regressão é usada para predizer o valor de uma variável Y (chamada de variável resposta ou dependente) baseado em uma ou mais variáveis X (variável explanatória ou independente). Se a regressão utiliza apenas uma variável explanatória, é chamada de regressão simples. O objetivo da regressão é representar a relação entre as variáveis resposta e explanatória por meio de uma equação matemática linear do tipo: \\(Y = \\beta_1 + \\beta_2X + \\epsilon\\) onde \\(\\beta_1\\) é a interceptação da reta com o eixo vertical e \\(\\beta2\\) o coeficiente de inclinação associado à variável explanatória. Tais elementos são chamados coeficientes da regressão. O termo \\(\\epsilon\\) representa o termo do erro, que é a parte de Y que a regressão é incapaz de explicar (por existir outras variáveis que explicariam Y mas que não foram incorporadas ao modelo). Neste módulo, usaremos como exemplo o dataset do Kaggle de Bicicletas compartilhadas em Washington D.C., nos Estados Unidos. Baixe o arquivo zip do Kaggle e leia o README para entender o que o dataset representa e suas variáveis significam. Vamos importar apenas df &lt;- readr::read_csv(&quot;https://raw.githubusercontent.com/sillasgonzaga/curso_series_temporais/master/data/Bike-Sharing-Dataset/day.csv&quot;) # dando olhada nos dados # glimpse(df) Seguindo o que aprendemos a partir da leitura do README, vamos fazer algumas transformações de colunas antes de proceder com a modelagem: df_transf &lt;- df %&gt;% # remover colunas irrelevantes select(-c(instant, workingday)) %&gt;% # renomear algumas colunas rename( estacao = season, total = cnt, year = yr, month = mnth ) %&gt;% # mudar weekday, que começa a contar do zero mutate(weekday = weekday + 1) %&gt;% # transformar a variavel de feriado para texto mutate(holiday = as.character(holiday)) %&gt;% # mudar os valores de algumas variaveis mutate( # substituir o codigo do ano pelo ano real year = lubridate::year(dteday), # adicionar um leading zero no mês month = str_pad(month, width = 2, side = &quot;left&quot;, pad = &quot;0&quot;), # converter weathersit para variavel do tipo factor weathersit = factor(weathersit, levels = 1:4, labels = c(&quot;muito bom&quot;, &quot;bom&quot;, &quot;ruim&quot;, &quot;muito ruim&quot;)), # converter dia da semana para variavel do tipo factor weekday = factor(weekday, levels = 1:7, labels = c(&quot;Dom&quot;, &quot;Seg&quot;, &quot;Ter&quot;, &quot;Qua&quot;, &quot;Qui&quot;, &quot;Sex&quot;, &quot;Sab&quot;)), # fazer o mesmo para estacao estacao = factor(estacao, levels = 1:4, labels = c(&quot;Primavera&quot;, &quot;Verao&quot;, &quot;Outono&quot;, &quot;Inverno&quot;)), # converter colunas numericas para escala normal (não-normalizada) temp = temp * 41, atemp = atemp * 50, hum = hum * 100, windspeed = windspeed * 67 ) Estamos interessados em entender o que influencia a demanda de bicicletas alugadas por dia. 2.1 Análise exploratória O primeiro passo para entendermos nossa variável de estudo é criar um gráfico da série: df_transf %&gt;% ggplot(aes(x = dteday, y = total)) + geom_line() + # adicionar curva de tendencia geom_smooth(se = FALSE) + theme_bw() + # quebrar eixo x em 1 mes scale_x_date(date_breaks = &quot;1 month&quot;, date_labels = &quot;%m/%Y&quot;, minor_breaks = NULL) + # inverter eixos theme(axis.text.x = element_text(angle = 90)) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; Apenas com o gráfico acima, podemos aprender uma série de insights interessantes: Parece haver múltiplas sazonalidades que afetam a demanda por bicicletas alugadas: dia da semana, mês, ano e estação do ano. Não existe um componente de tendência linear, pois as altas e quedas são mais em função das sazonalidades descritas acima. Exercícios: - Como você faria para representar a estação do ano no gráfico acima? Teste duas abordagens: acrescente linhas verticas tracejadas marcando a transição das estações ou pinte a linha (usando aes) de acordo com a estação. - Explore com mais detalhes a distribuição da variável total em função de: - Dia da semana &amp; Feriado - Dia da semana &amp; Condição do tempo - Mês &amp; Estação do ano - Mês &amp; Ano 2.2 Correlação Correlação é um indicador estatístico que mede o nível de dependência linear entre duas variáveis. Está definida no intervalo \\([-1, +1]\\). Se a correlação é negativa, indica que as variáveis são inversamente proporcinais: quando uma aumenta, a outra diminui. Se é positiva, indica que as variáveis são diretamente proporcionais. Medir a correlação no R é muito simples: # Usando a função cor cor(df_transf$total, df_transf$temp) ## [1] 0.627494 cor(df_transf$temp, df_transf$atemp) ## [1] 0.9917016 Como poderia se esperar, as variáveis temp e atemp são praticamente a mesma, apresentando uma correlação quase igual a 1. Isso, em regressão, é um problema chamado multicolinearidade. Por isso, é necessário remover uma delas: df_transf &lt;- df_transf %&gt;% select(-atemp) No entanto, é possível analisar todos os pares possíveis entre as variáveis de uma matriz numérica: df_transf %&gt;% select_if(is.numeric) %&gt;% select(-year) %&gt;% cor() ## temp hum windspeed casual registered ## temp 1.0000000 0.12696294 -0.1579441 0.54328466 0.5400120 ## hum 0.1269629 1.00000000 -0.2484891 -0.07700788 -0.0910886 ## windspeed -0.1579441 -0.24848910 1.0000000 -0.16761335 -0.2174490 ## casual 0.5432847 -0.07700788 -0.1676133 1.00000000 0.3952825 ## registered 0.5400120 -0.09108860 -0.2174490 0.39528245 1.0000000 ## total 0.6274940 -0.10065856 -0.2345450 0.67280443 0.9455169 ## total ## temp 0.6274940 ## hum -0.1006586 ## windspeed -0.2345450 ## casual 0.6728044 ## registered 0.9455169 ## total 1.0000000 Um incremento ainda melhor é usar o pacote GGally para plotar uma matriz de correlação: df_transf %&gt;% select_if(is.numeric) %&gt;% select(-c(year, casual, registered)) %&gt;% GGally::ggpairs(progress = FALSE) Percebe-se pela matriz de correlação (e principalmente pelo gráfico) que talvez só valeria a pena usar como variáveis explanatórias do nosso objeto de estudo a temperatura do dia. 2.3 Modelagem por regressão simples No R, é bem simples ajustar um modelo de regressão. Usando a variável temp como explanatória e total como resposta, um modelo é construído da seguinte maneira: modelo.simples &lt;- lm(total ~ temp, data = df_transf) summary(modelo.simples) ## ## Call: ## lm(formula = total ~ temp, data = df_transf) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4615.3 -1134.9 -104.4 1044.3 3737.8 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1214.642 161.164 7.537 1.43e-13 *** ## temp 161.969 7.444 21.759 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1509 on 729 degrees of freedom ## Multiple R-squared: 0.3937, Adjusted R-squared: 0.3929 ## F-statistic: 473.5 on 1 and 729 DF, p-value: &lt; 2.2e-16 Com o modelo criado, é possível descrever a relação entre consumo e n_carteiras matematicamente por meio da seguinte equação: \\(total = 1214.642 + 161.969 \\times temperatura\\) Vamos deixar para analisar os diagnósticos da regressão no próximo item: 2.4 Regressão multivariada Suponha também que você deseja incorporar as outras variáveis que detectamos que são importantes para modelar a variável da quantidade de bikes alugadas: # sintaxe para incluir todas as variaveis como regressoras menos uma (dteday) modelo.multiplo &lt;- lm(total ~ . - dteday - casual - registered, data = df_transf) summary(modelo.multiplo) ## ## Call: ## lm(formula = total ~ . - dteday - casual - registered, data = df_transf) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3960.9 -350.9 74.1 456.0 2919.9 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -4.057e+06 1.171e+05 -34.634 &lt; 2e-16 *** ## estacaoVerao 8.893e+02 1.795e+02 4.954 9.12e-07 *** ## estacaoOutono 8.322e+02 2.132e+02 3.903 0.000104 *** ## estacaoInverno 1.579e+03 1.810e+02 8.722 &lt; 2e-16 *** ## year 2.018e+03 5.823e+01 34.660 &lt; 2e-16 *** ## month02 1.369e+02 1.437e+02 0.952 0.341396 ## month03 5.451e+02 1.655e+02 3.294 0.001036 ** ## month04 4.565e+02 2.476e+02 1.844 0.065667 . ## month05 7.235e+02 2.675e+02 2.704 0.007010 ** ## month06 4.906e+02 2.818e+02 1.741 0.082133 . ## month07 8.404e+00 3.134e+02 0.027 0.978613 ## month08 4.049e+02 3.015e+02 1.343 0.179700 ## month09 9.839e+02 2.647e+02 3.717 0.000217 *** ## month10 5.209e+02 2.416e+02 2.156 0.031432 * ## month11 -1.114e+02 2.308e+02 -0.482 0.629621 ## month12 -8.439e+01 1.822e+02 -0.463 0.643439 ## holiday1 -6.036e+02 1.801e+02 -3.352 0.000845 *** ## weekdaySeg 2.149e+02 1.095e+02 1.962 0.050133 . ## weekdayTer 3.091e+02 1.072e+02 2.884 0.004041 ** ## weekdayQua 3.774e+02 1.075e+02 3.512 0.000473 *** ## weekdayQui 3.852e+02 1.076e+02 3.581 0.000366 *** ## weekdaySex 4.286e+02 1.073e+02 3.996 7.12e-05 *** ## weekdaySab 4.387e+02 1.066e+02 4.116 4.32e-05 *** ## weathersitbom -4.652e+02 7.708e+01 -6.035 2.57e-09 *** ## weathersitruim -1.981e+03 1.967e+02 -10.075 &lt; 2e-16 *** ## temp 1.094e+02 1.004e+01 10.896 &lt; 2e-16 *** ## hum -1.518e+01 2.922e+00 -5.196 2.68e-07 *** ## windspeed -4.366e+01 6.062e+00 -7.202 1.53e-12 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 769.5 on 703 degrees of freedom ## Multiple R-squared: 0.848, Adjusted R-squared: 0.8422 ## F-statistic: 145.3 on 27 and 703 DF, p-value: &lt; 2.2e-16 Valores altos de impostos aparentam estar associados com valores baixos de consumo. Para adicionar uma nova variável ao modelo, fazemos: # Usando o pacote broom para formatar o output dos modelos de regressao # concatenando os dois modelos em um dataframe so # metricas dos regressores modelo.simples %&gt;% tidy() ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 1215. 161. 7.54 1.43e-13 ## 2 temp 162. 7.44 21.8 2.81e-81 modelo.multiplo %&gt;% tidy() ## # A tibble: 28 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) -4056781. 117133. -34.6 3.97e-154 ## 2 estacaoVerao 889. 180. 4.95 9.12e- 7 ## 3 estacaoOutono 832. 213. 3.90 1.04e- 4 ## 4 estacaoInverno 1579. 181. 8.72 1.97e- 17 ## 5 year 2018. 58.2 34.7 2.85e-154 ## 6 month02 137. 144. 0.952 3.41e- 1 ## 7 month03 545. 165. 3.29 1.04e- 3 ## 8 month04 456. 248. 1.84 6.57e- 2 ## 9 month05 724. 268. 2.70 7.01e- 3 ## 10 month06 491. 282. 1.74 8.21e- 2 ## # … with 18 more rows # metricas do modelo modelo.simples %&gt;% glance() ## # A tibble: 1 x 11 ## r.squared adj.r.squared sigma statistic p.value df logLik AIC ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.394 0.393 1509. 473. 2.81e-81 2 -6387. 12780. ## # … with 3 more variables: BIC &lt;dbl&gt;, deviance &lt;dbl&gt;, df.residual &lt;int&gt; modelo.multiplo %&gt;% glance() ## # A tibble: 1 x 11 ## r.squared adj.r.squared sigma statistic p.value df logLik AIC ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.848 0.842 770. 145. 1.49e-266 28 -5881. 11820. ## # … with 3 more variables: BIC &lt;dbl&gt;, deviance &lt;dbl&gt;, df.residual &lt;int&gt; Agora vamos à análise dos indicadores da regressão: 2.4.1 Hipótese nula da regressão A presença de um valor-p indica que existe uma hipótese nula sendo testada. Na regressão linear, a hipótese nula é a de que os coeficientes das variáveis explanatórias são iguais a zero. A hipótese alternativa é a de que os coeficientes não são iguais a zero, ou seja, existe uma relação matemático entre as variáveis do modelo. 2.4.2 valor-p Nós podemos considerar um modelo linear estatisticamente significante apenas se os valores-p, tanto dos coeficientes como do modelo, são menores que um nível de significância pré-determinado, que idealmente é 0,05. 2.4.3 R-quadrado e R-quadrado ajustado R-quadrado é a proporção da variação da variável resposta que é explicada pelo modelo. Quanto maior, melhor o modelo, supostamente. Se continuarmos adicionando variáveis ao modelo de regressão, o R-quadrado apenas tende a crescer, intuitivamente. Isso acontecerá mesmo que a variável explanatória adicionada não seja significante. Para evitar esse problema que tornaria a comparação entre modelos praticamente inviável, o R-quadrado ajustado “penaliza” o valor do R-quadrado pelo número de variáveis adicionadas. Semelhantemente ao R-quadrado, quanto maior, melhor. 2.4.4 Análise dos resíduos Um indicador visual da qualidade de um modelo é a distribuição dos modelos: um bom modelo apresentará resídos que seguem uma distribuição normal com média 0. Um modelo de regressão pressupõe que seus resíduos (subtração entre o valor real e o ajustado) seguem uma distribuição normal e não possuem nenhum tipo de relação matemática com os regressores do modelo (ou mesmo com variáveis independentes não usadas no modelo). forecast::checkresiduals(modelo.multiplo) ## ## Breusch-Godfrey test for serial correlation of order up to 31 ## ## data: Residuals ## LM test = 148.71, df = 31, p-value &lt; 2.2e-16 2.5 Regressão como modelo preditivo Um dos objetivos da regressão, além de descrever matematicamente a relação entre duas ou mais variáveis, é prever o valor da variável dependente baseado em novos valores da variável independente. Não é possível afirmar que um modelo apresentará um bom desempenho preditivo analisando apenas as métricas da regressão do tópico anterior. É necessário testar o modelo em dados que ele nunca viu. A prática comum em Data Science é de separar o conjunto de dados que se tem em mãos em dois conjuntos: o de treino, que será usado para construir o modelo, e o de teste, que será usado como input do modelo para avaliar sua acurácia. Após obter as previsões, deve-se usar uma ou mais métricas de erro (ver capítulo posterior) para avaliar a precisão do modelo. indice_teste &lt;- tail(1:nrow(df_transf), 60) treino &lt;- df_transf[-indice_teste, ] # model training data teste &lt;- df_transf[indice_teste, ] # test data # construindo os dois modelos, mantendo o teste de fora modelo.simples &lt;- lm(total ~ temp, data = treino) modelo.multiplo &lt;- lm(total ~ . - dteday - casual - registered, data = treino) # calcular previsao baseado no dataframe de teste prev.simples &lt;- predict(modelo.simples, teste) prev.mult &lt;- predict(modelo.multiplo, teste) # uma das metricas é correlação entre previsto e real: real &lt;- teste$total # outra metrica é o MAPE ape &lt;- function(yreal, yprev) { abs((yreal - yprev)/yreal) } mean(ape(yreal = real, yprev = prev.simples)) ## [1] 0.4816825 mean(ape(yreal = real, yprev = prev.mult)) ## [1] 0.3890409 Os dois modelos apresentam resultados semelhantes de erro. Portanto, pelo menos para este teste, não houve um aumento significativo de acurácia no modelo ao incorporar a variável imposto como explanatória. 2.6 Referências Pressupostos sobre regressão linear; Datasets para você praticar regressão linear. Exercícios: - Importe este dataset de consumo de petróleo para o R. - Qual a variável resposta? - Quais variáveis explanatórias incluir no modelo? - Quais gráficos para analisar as variáveis e os modelos? "],
["avaliacao.html", "Capítulo 3 Avaliação de precisão de modelos de séries temporais 3.1 Medidas de precisão 3.2 Desempenho fora de amostra: Overfitting e underfitting 3.3 Referências", " Capítulo 3 Avaliação de precisão de modelos de séries temporais Suponha que \\(y_i\\) seja uma observação real de uma série temporal no período \\(i\\) e \\(\\hat{y}_i\\) seja uma previsão de \\(y_i\\). O erro de previsão no ponto \\(i\\) é simplesmente \\(e_i = y_i - \\hat{y}_i\\). Para calcular o erro “geral” de um modelo preditivo de série temporal, diversas existem diversas métricas. Para demonstrar o uso dessas métricas, usaremos uma série temporal obtida pelo pacote BETS: # carregar pacotes usados # install.packages(&quot;BETS&quot;) library(BETS) library(forecast) library(tidyverse) # baixar serie temporal de exemplo deste capitulo BETSsearch(&quot;industria&quot;, periodicity = &quot;M&quot;, view = FALSE) %&gt;% head(10) %&gt;% knitr::kable() ## ## BETS-package: Found 139 out of 18706 time series. code description unit periodicity start last_value source 11073 Industrial production (2002=100) - Northeast region Index M 31/01/1991 feb/2014 IBGE 11074 Industrial production (1991=100) - Amazonas Index M 31/01/1991 feb/2014 IBGE 11075 Industrial production (1991=100) - Pará Index M 31/01/1991 feb/2014 IBGE 11076 Industrial production (1991=100) - Ceará - 11076 Index M 31/01/1991 feb/2014 IBGE 11077 Industrial production (1991=100) - Pernambuco - 11077 Index M 31/01/1991 feb/2014 IBGE 11078 Industrial production (2002=100) - Bahia Index M 31/01/1991 feb/2014 IBGE 11079 Industrial production (2002=100) - Minas Gerais Index M 31/01/1991 feb/2014 IBGE 11080 Industrial production (2002=100) - Espírito Santo Index M 31/01/1991 feb/2014 IBGE 11081 Industrial production (2002=100) - Rio de Janeiro Index M 31/01/1991 feb/2014 IBGE 11082 Industrial production (2002=100) - São Paulo Index M 31/01/1991 feb/2014 IBGE A busca pela string “indústria” nos retorna alguns datasets sobre o tema. Usaremos a série de número 1404, que é sobre o consumo de energia elétrica no Brasil em GWh e de frequência mensal. energia &lt;- BETSget(1404) # Salvar para uso posterior saveRDS(energia, &quot;data/ts_energia.Rda&quot;) # plotando a serie para a conhecer autoplot(energia) + labs(x = NULL, y = &quot;Consumo (Gwh)&quot;) É possível perceber que a série apresenta uma tendência contínua de alta desde o início. As pequenas variações podem ser interpretadas como componenente sazonal, o que é mostrado no gráfico de decomposição: # analisando os componentes: energia %&gt;% decompose() %&gt;% autoplot Pelo gráfico, temos que tanto o componente de tendência quanto o de sazonalidade são bem evidentes na série. Voltando ao tema do capítulo. Para ilustrar o conceito das métricas tratadas, vamos nos utilizar de dois modelos de previsão: um complexo, de suavização exponencial, e outro simples, um sazonal ingênuo. mod.rn &lt;- ets(energia) mod.ingenuo.saz &lt;- snaive(energia, h = 12) # plotando os dois ajustes junto à curva original autoplot(energia) + # plota modelo de Suavização exponencial geom_line(aes(y = mod.rn$fitted, color = &quot;Suavização exponencial&quot;), linetype = &quot;dashed&quot;, alpha = 0.7) + # plotar modelo sazonal ingenuo geom_line(aes(y = mod.ingenuo.saz$fitted, color = &quot;Ingênuo sazonal&quot;), linetype = &quot;dashed&quot;, alpha = 0.5) + # redefinir cores scale_color_manual(name = NULL, values = c(&quot;blue&quot;, &quot;red&quot;)) + theme_classic() + # posicionar legenda theme(legend.position = &quot;bottom&quot;) Pelo gráfico, poderíamos concluir que o ajuste obtido com o modelo de Suavização exponencial é superior ao sazonal ingênuo, que costuma errar o nível da série temporal. Contudo, para ter certeza disso, precisamos avaliar os modelos com alguma métrica de precisão (ou de erro). 3.1 Medidas de precisão Podemos dividir as métricas de precisão em dois grupos: os baseados em escala e os baseados em percentuais. 3.1.1 Métricas baseadas em escala Você deve ter observado que \\(e_i\\) possui a mesma escala da variável resposta \\(y_i\\). Isto é, se o objeto do modelo é prever o consumo de gasolina de um carro, dado em litros, então o erro de previsão também será dado em litros. As duas métricas de erro baseadas em escala são o MAE (erro médio absoluto) e o RMSE (raiz do erro quadrático médio), calculados como: \\(MAE = media(|e_i|)\\) \\(RMSE = \\sqrt(media(e_i^2))\\) Entre as duas métricas, a MAE é mais fácil e simples de explicar. Contudo, o output da RMSE representa o que vários algoritmos de previsão são escritos para minimizar. Ela pode ser compreendida como uma medida análoga ao desvio padrão do modelo. 3.1.2 Métricas baseadas em percentuais Se o objetivo de uma análise é avaliar a qualidade de ajuste e a acurácia de diferentes modelos para uma mesma série, as métricas baseadas em escala não são um problema. Porém, quando se deseja avaliar a performance de um (ou mais) modelo para diversas séries temporais de escalas diferentes (é muito incomum que um conjunto grande de séries possuam a mesma escala, mesmo que tenham a mesma unidade de medida), deve-se optar pelas métricas baseadas em percentuais. Definindo \\(p_i = 100\\times e_i/y_i\\), temos que a métrica mais comum é o MAPE (erro absoluto percentual médio): \\(MAPE = media(|p_i|)\\) Contudo, o MAPE possui uma grande desvantagem: é indefinido quando há pelo menos um caso em que \\(y_i = 0\\). Para contornar essa situação e poder usar uma métrica de erro independente de escala em uma série temporal que possa apresentar valores muito próximos ou iguais a zero, podemos usar o MASE (erro médio de escala absoluto), que é a proporção de erros de previsão em relação aos erros de uma previsão ingênuo. A função forecast::accuracy() retorna todas essas métricas e mais algumas outras para um dado modelo preditivo: # modelo de Suavização exponencial accuracy(mod.rn) ## ME RMSE MAE MPE MAPE MASE ## Training set 20.455 265.5196 197.8673 0.177949 2.042775 0.3594056 ## ACF1 ## Training set 0.0222034 # modelo ingenuo sazonal accuracy(mod.ingenuo.saz) ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set 234.2484 730.5153 550.5403 2.392288 5.322205 1 0.8895264 3.2 Desempenho fora de amostra: Overfitting e underfitting Conforme discutido no capítulo anterior, a melhor maneira de avaliar o desempenho preditivo de um modelo de séries temporais é avaliar sua performance em dados nunca vistos pelo modelo. Repetimos o procedimento já descrito nos dois modelos usados como exemplo: # vamos construir dois modelos para serem comparados: um de Suavização exponencial e # um modelo ingenuo treino &lt;- window(energia, end = c(2015, 12)) teste &lt;- window(energia, start = c(2016, 1), end = c(2016, 12)) # vamos &quot;esconder&quot; o conjunto de teste dos modelos: mod.rn &lt;- nnetar(treino) %&gt;% forecast(h = length(teste)) mod.ingenuo.saz &lt;- snaive(treino, h = 12) %&gt;% forecast(h = length(teste)) # a funcao accuracy aceita como argumento um vetor numerico de teste, sobre o qual # a acuracia do modelo sera avaliada accuracy(mod.rn, teste) %&gt;% round(3) ## ME RMSE MAE MPE MAPE MASE ACF1 Theil&#39;s U ## Training set -0.224 324.163 242.01 -0.110 2.432 0.422 0.104 NA ## Test set -454.840 525.610 454.84 -3.366 3.366 0.794 0.279 1.356 accuracy(mod.ingenuo.saz, teste) %&gt;% round(3) ## ME RMSE MAE MPE MAPE MASE ACF1 Theil&#39;s U ## Training set 255.648 753.274 572.810 2.616 5.606 1.000 0.887 NA ## Test set -383.750 567.367 412.917 -2.868 3.082 0.721 0.656 1.443 Os resultados são no mínimo interessantes: enquanto o desempenho do modelo de Suavização exponencial é bem melhor na série de treino (possui MAE e MAPE mais de duas vezes menor), é o modelo sazonal ingênuo que apresenta o melhor desempenho na série de teste, com exceção do RMSE. Esse é um exemplo claro que ilustra os conceitos de overfitting e underfitting, também conhecido como o tradeoff entre viés e variância. Conceitualmente, viés é o erro que ocorre quando o algoritmo do modelo preditivo assume pressupostos errados (ou demasiadamente simples). Um alto viés implica na possibilidade de que o modelo não incorpore elementos importantes do conjunto de treino, causando o underfitting. Variância é o erro oriundo de pequenas variações no conjunto de treino. Quando um modelo é complexo demais a ponto de tentar representar todas as pequenas variações observadas no conjunto de treino, temos o overfitting. Nos nossos dois modelos de estudo, apenas analisando os resultados de acurácia nos conjuntos de treino e teste, podemos observar que o modelo de Suavização exponencial sofre de overfitting, pois apresenta um excelente desempenho na série de treino mas um desempenho inferior na série de teste comparado com um modelo simples, que compreensivelmente sofre de underfitting. Essa representação visual nos ajuda a entender esses dois conceitos: Também é possível analisar a qualidade das previsões dos modelos graficamente: # plotando as previsoes contra o real: autoplot(teste) + geom_point() + geom_line(aes(y = mod.rn$mean, color = &quot;Suavização exponencial&quot;), linetype = &quot;dashed&quot;) + geom_line(aes(y = mod.ingenuo.saz$mean, color = &quot;Ingênuo sazonal&quot;), linetype = &quot;dashed&quot;) + scale_color_manual(name = NULL, values = c(&quot;blue&quot;, &quot;red&quot;)) + theme(legend.position = &quot;bottom&quot;) Dá para observar que o modelo ingênuo sazonal apresenta um desempenho praticamente perfeito no segundo semestre de 2016, compensando o erro alto no primeiro semestre. Será que isso é um padrão? É mais fácil prever o segundo semestre do que o primeiro? Será que, caso o modelo ingênuo sazonal seja sempre melhor no segundo semestre e o de Suavização exponencial no primeiro, é possível construir um modelo de previsão misto (ou um ensemble model) que se beneficie dessa informação? Fica o exercício para o leitor. 3.3 Referências Ótimo post no blog do Regis sobre o tradeoff entre viés e variância; ANOTHER LOOK AT FORECAST-ACCURACY METRICS FOR INTERMITTENT DEMAND, um paper do Rob Hyndman sobre as principais métricas de erros usadas em séries temporais. Exercícios: - Baixe uma série temporal usando o BETS (pode ser a mesma do capítulo 01) e ajuste três modelos nela: ARIMA, Suavizacao exponencial e Media simples. - Calcule a acurácia dentro e fora da amostra. "],
["decomposicao.html", "Capítulo 4 Decomposição de Séries Temporais 4.1 Médias móveis 4.2 Decomposição clássica 4.3 Outros tipos de decomposição", " Capítulo 4 Decomposição de Séries Temporais # install.packages(&quot;seasonal&quot;) library(BETS) library(forecast) library(lubridate) library(tidyverse) library(magrittr) library(seasonal) Séries Temporais podem exibir uma grande variedade de padrões que podem ser modelados separadamentes, o que pode ajudar o analista a entender melhor os dados e até mesmo a melhorar as previsões. Já vimos no capítulo introdutório que uma série temporal possui três tipos de padrão: tendência, sazonalidade e ciclo. Se assumirmos que a série segue um modelo aditivo, então, matematicamente, ela pode ser descrita pela equação \\(y_t = S_t + T_t + E_t\\), onde \\(E_t\\) é o componente do erro no período \\(t\\). Se a série for melhor descrita por um modelo multiplicativo, então a equação vira \\(y_t = S_t \\times T_t \\times E_t\\). Para se decidir se uma série segue um modelo aditivo ou multiplicativo (alguns algoritmos já calculam isso internamente), observe se a magnitude dos períodos sazonais ou a variância da tendência cresce conforme o nível (valores absolutos) da série cresce. Por exemplo: # simulando uma série de modelo aditivo set.seed(123) x &lt;- 1:500 + c(rnorm(250, 50, 25), rnorm(250, 50, 25)) plot(x, type = &quot;l&quot;) # modelo multiplicativo a &lt;- rep(1, 500) b &lt;- 1:500/8 set.seed(123) x2 &lt;- pmap(list(a, b), rnorm, mean = 0) %&gt;% as.numeric() x &lt;- 1:500 + x2 plot(x, type = &quot;l&quot;) No segundo gráfico, vemos que, para valores maiores da série temporal, a variância dos dados é maior. 4.1 Médias móveis Embora seja meio datada e tenha dado espaço para técnicas mais avançadas de decomposição, a média móvel é a base de muitos métodos de análises de séries temporais e uma importante etapa para estimar o componente de tendência de uma série. Vamos voltar a analisar a série temporal baixada por meio do BETS: energia &lt;- readRDS(&quot;data/ts_energia.Rda&quot;) # plotando a serie contra uma media movel de 3 meses plot(energia) ma(energia, 3) %&gt;% lines(col = &quot;red&quot;, lwd = 1) # a media movel de 3 meses nao foi suficiente. vamos aumentar o periodo ma(energia, 12) %&gt;% lines(col = &quot;blue&quot;, lwd = 2) ma(energia, 24) %&gt;% lines(col = &quot;green&quot;, lwd = 3) A curva que apresenta menos flutuações sazonais é verde, referente à média móvel de 24 períodos. Mesmo assim, pode-se dizer que essa decomposição não foi satisfatória, devido a curva apresentar perturbações mesmo usando um período longo (24 meses) para sua estimação. 4.2 Decomposição clássica A técnica de decomposição clássica é um procedimento relativamente simples, mas depende da definição do usuário se a série temporal analisada segue um modelo aditivo ou multiplicativo. Calcule a média móvel da série temporal: # convertendo para dataframe df_energia &lt;- data.frame( data = seq.Date(from = as.Date(&quot;1979-01-01&quot;), by = &quot;month&quot;, length.out = length(energia)), st = energia ) # adicionando a media movel df_energia$media_movel &lt;- ma(energia, 24) Remova o componente de tendência da série. Caso seja o modelo seja aditivo, subtraia a série pela tendência. Caso seja multiplicativo, divida. df_energia$serie_sem_tend_adt &lt;- energia - df_energia$media_movel df_energia$serie_sem_tend_mult &lt;- energia / df_energia$media_movel Calcule a média da série sem tendência para cada período sazonal. # no caso dessa serie de exemplo, que possui frequencia igual a 12, # um periodo sazonal corresponde aos 12 meses do ano df_energia %&lt;&gt;% group_by(mes = month(data)) %&gt;% mutate(saz_adi = mean(serie_sem_tend_adt, na.rm = TRUE), saz_mult = mean(serie_sem_tend_mult, na.rm = TRUE)) %&gt;% ungroup() # é necessário verificar se os indices sazonais aditivos somam 0 e se os multiplicativos somam 12 df_energia$saz_adi %&gt;% unique %&gt;% sum ## [1] 6.252638 df_energia$saz_mult %&gt;% unique %&gt;% sum ## [1] 11.99492 # os indices sazonais nao somam zero, portanto precisamos rescalar o vetor: df_energia %&lt;&gt;% mutate(saz_adi = scale(saz_adi)) %&gt;% ungroup() # checando novamente df_energia$saz_adi %&gt;% unique %&gt;% sum ## [1] 0.1081548 Calcular o componente de erro (restante) # se for aditivo, e = y_t - T_t - S_t df_energia %&lt;&gt;% mutate( erro_adi = serie_sem_tend_adt - saz_adi, erro_mult = serie_sem_tend_mult / saz_mult ) Vamos comparar os dois componentes de erro obtidos: layout(matrix(c(1,1,2,3), 2, 2, byrow = TRUE)) plot(df_energia$erro_adi, type = &quot;l&quot;) lines(df_energia$erro_mult, type = &quot;l&quot;, col = &quot;red&quot;) hist(df_energia$erro_adi, main = &quot;Distribuição do erro aditivo&quot;) hist(df_energia$erro_mult, main = &quot;Distribuição do erro multiplicativo&quot;) Outro gráfico que pode ser usado para comparar o erro aleatório é o de autocorrelação: par(mfrow = c(1,2)) df_energia %$% acf(erro_adi, na.action = na.omit) df_energia %$% acf(erro_mult, na.action = na.omit) # verificando qual dos dois possui a menor autocorrelacao total df_energia %$% acf(erro_adi, na.action = na.omit, plot = FALSE)$acf^2 %&gt;% sum ## [1] 2.67057 df_energia %$% acf(erro_mult, na.action = na.omit, plot = FALSE)$acf^2 %&gt;% sum ## [1] 2.401482 Pela análise da autocorrelação, a decomposição multiplicativa parece ser mais apropriada. 4.3 Outros tipos de decomposição 4.3.1 Pacote seasonal O pacote seasonal, disponível no CRAN, implementa uma interface ao algoritmo e software X-13-ARIMA-SEATS, desenvolvido pelo US Census Bureau. Possui recursos como seleção automática do modelo ARIMA, detecção de outliers e suporte para feriados definidos pelo usuário, como Carnaval e Páscoa. Um rápido uso do pacote seasonal é mostrado abaixo: m &lt;- seas(energia) # resumo sobre o modelo summary(m) ## ## Call: ## seas(x = energia) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## Leap Year 5.861e+01 5.619e+01 1.043 0.296924 ## Mon -2.526e+01 1.748e+01 -1.445 0.148339 ## Tue -1.817e+01 1.746e+01 -1.040 0.298218 ## Wed -5.446e+01 1.746e+01 -3.119 0.001812 ** ## Thu 9.225e+01 1.746e+01 5.283 1.27e-07 *** ## Fri -3.713e+01 1.763e+01 -2.106 0.035165 * ## Sat 1.139e+01 1.748e+01 0.652 0.514642 ## Easter[15] -1.299e+02 3.732e+01 -3.480 0.000501 *** ## AO1990.May -9.306e+02 1.632e+02 -5.704 1.17e-08 *** ## LS2001.Jul -1.707e+03 1.959e+02 -8.713 &lt; 2e-16 *** ## LS2003.Dec 8.830e+02 1.961e+02 4.502 6.72e-06 *** ## AO2008.Dec 1.005e+03 2.038e+02 4.931 8.18e-07 *** ## LS2008.Dec -2.100e+03 2.454e+02 -8.557 &lt; 2e-16 *** ## MA-Nonseasonal-01 2.702e-01 4.459e-02 6.059 1.37e-09 *** ## MA-Seasonal-12 7.701e-01 3.122e-02 24.672 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## SEATS adj. ARIMA: (0 1 1)(0 1 1) Obs.: 471 Transform: none ## AICc: 6264, BIC: 6329 QS (no seasonality in final):1.115 ## Box-Ljung (no autocorr.): 34.74 . Shapiro (normality): 0.9928 * ## Messages generated by X-13: ## Notes: ## - Unable to test AO2008.Dec due to regression matrix ## singularity. # plotando o modelo plot(m) # retornando as componentes individuais da serie: final(m) %&gt;% head(20) # serie sem tendencia ## Jan Feb Mar Apr May Jun Jul ## 1980 5005.965 5051.760 5044.333 5001.809 4997.515 5087.738 5094.600 ## 1981 5390.172 5297.773 5385.770 5138.128 5218.988 5029.885 5080.190 ## Aug Sep Oct Nov Dec ## 1980 5163.362 5204.023 5267.454 5271.295 5327.045 ## 1981 4950.570 trend(m) %&gt;% head(20) # tendencia da serie ## Jan Feb Mar Apr May Jun Jul ## 1980 5008.057 5028.672 5030.321 5021.832 5033.681 5069.899 5111.983 ## 1981 5337.207 5327.410 5287.642 5220.365 5153.433 5090.446 5029.089 ## Aug Sep Oct Nov Dec ## 1980 5157.802 5206.487 5248.918 5284.289 5319.683 ## 1981 4956.184 irregular(m) %&gt;% head(20) # erro aleatorio ## Jan Feb Mar Apr May Jun ## 1980 -2.091950 23.088065 14.012675 -20.022918 -36.166350 17.839499 ## 1981 52.964646 -29.636641 98.127233 -82.237707 65.554973 -60.560923 ## Jul Aug Sep Oct Nov Dec ## 1980 -17.382187 5.559417 -2.464073 18.536265 -12.994203 7.361955 ## 1981 51.100318 -5.613686 4.3.2 Decomposição STL O método STL funciona apenas para decomposições aditivas. Aplicá-la no R é muito fácil, usando a função stl: energia %&gt;% stl(s.window = &quot;periodic&quot;) %&gt;% #raramente este argumento sera diferente plot "],
["suavizacao.html", "Capítulo 5 Suavização exponencial 5.1 Suavização simples 5.2 Linear de Holt 5.3 Holt-winter aditivo e multiplicativo 5.4 Seleção automática do melhor modelo de suavização exponencial", " Capítulo 5 Suavização exponencial Métodos de suavização exponencial produzem previsões a partir de médias ponderadas de observações passadas, onde o peso associado a cada observação cai a medida em que se recua mais no tempo. Ou seja, quanto mais recente a observação, maior será seu peso no modelo preditivo. Apesar de simples, é usado em larga escala nas mais diversas aplicações. Para este capítulo, será usada como exemplo a série temporal da cotação do dólar, obtida com o pacote quantmod: library(tidyverse) library(forecast) library(lubridate) energia &lt;- readRDS(&quot;data/ts_energia.Rda&quot;) 5.1 Suavização simples A suavização simples exponencial é considerada útil para séries sem tendência ou sazonalidade. No R, ela é implementada pela função forecast::ses() Levando em conta que o modelo ingênuo (naive model) atribui peso 1 para a última observação e o modelo da média simples atribui peso igual para todas as observações passadas, a suavização simples poderia ser descrita como um meio termo entre ambos. Sua formulação matemática não é complexa: \\(\\hat{y}_{T+1|T} = \\alpha y_t + \\alpha (1 - \\alpha)y_{T-1} + \\alpha (1 - \\alpha)^2y_{T-2} + ...\\) O parâmetro \\(\\alpha\\) é chamado de parâmetro de suavização e está definido no intervalo de 0 a 1. Por exemplo: alpha &lt;- 0.2 for (i in 1:5) print((1 - alpha)^i) ## [1] 0.8 ## [1] 0.64 ## [1] 0.512 ## [1] 0.4096 ## [1] 0.32768 alpha &lt;- 0.8 for (i in 1:5) print((1 - alpha)^i) ## [1] 0.2 ## [1] 0.04 ## [1] 0.008 ## [1] 0.0016 ## [1] 0.00032 Percebe-se pelos resultados da simulação acima que quanto maior o parâmetro \\(\\alpha\\), maior é o peso dado à observação imediatamente mais recente e menor o dado às demais. O valor de \\(\\alpha\\) pode ser “definido” subjetivamente, utilizando conhecimentos empíricos. Contudo, a maneira mais precisa de escolher esse valor é por meio de um algoritmo de otimização, que estimará \\(\\alpha\\) a partir dos dados obtidos Suponha que não façamos a mínima ideia do melhor valor de \\(\\alpha\\) para a série temporal da cotação do dólar. Vamos testar três valores: alpha1 &lt;- ses(energia, alpha = 0.1, h = 6) alpha2 &lt;- ses(energia, alpha = 0.5, h = 6) alpha3 &lt;- ses(energia, alpha = 0.9, h = 6) # calculando o erro de cada ajuste list(alpha1, alpha2, alpha3) %&gt;% map(accuracy) ## [[1]] ## ME RMSE MAE MPE MAPE MASE ## Training set 189.1023 566.3227 452.3437 1.852651 4.394329 0.821636 ## ACF1 ## Training set 0.7750762 ## ## [[2]] ## ME RMSE MAE MPE MAPE MASE ## Training set 38.04937 379.2963 279.4255 0.3436042 2.740185 0.5075478 ## ACF1 ## Training set 0.4246183 ## ## [[3]] ## ME RMSE MAE MPE MAPE MASE ## Training set 21.28641 344.4563 257.3424 0.1862282 2.533822 0.4674361 ## ACF1 ## Training set 0.07787846 plot(alpha1, plot.conf=FALSE, ylab = &quot;&quot;, main=&quot;&quot;, fcol=&quot;white&quot;) lines(fitted(alpha1), col=&quot;blue&quot;) lines(fitted(alpha2), col=&quot;red&quot;) lines(fitted(alpha3), col=&quot;green&quot;) lines(alpha1$mean, col=&quot;blue&quot;, type=&quot;o&quot;) lines(alpha2$mean, col=&quot;red&quot;, type=&quot;o&quot;) lines(alpha3$mean, col=&quot;green&quot;, type=&quot;o&quot;) legend(&quot;topleft&quot;,lty=1, col=c(1,&quot;blue&quot;,&quot;red&quot;,&quot;green&quot;), c(&quot;serie original&quot;, expression(alpha == 0.1), expression(alpha == 0.5), expression(alpha == 9)), pch=1) # qual o valor otimo encontrado para alpha nesse caso? ses(energia) %&gt;% summary ## ## Forecast method: Simple exponential smoothing ## ## Model Information: ## Simple exponential smoothing ## ## Call: ## ses(y = energia) ## ## Smoothing parameters: ## alpha = 0.9881 ## ## Initial states: ## l = 4806.6943 ## ## sigma: 344.0853 ## ## AIC AICc BIC ## 8405.052 8405.103 8417.516 ## ## Error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set 19.44131 343.3539 259.5568 0.1690397 2.565129 0.4714584 ## ACF1 ## Training set -0.002095396 ## ## Forecasts: ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## Apr 2019 13854.63 13413.67 14295.60 13180.24 14529.03 ## May 2019 13854.63 13234.72 14474.55 12906.55 14802.72 ## Jun 2019 13854.63 13096.91 14612.36 12695.79 15013.48 ## Jul 2019 13854.63 12980.56 14728.70 12517.86 15191.41 ## Aug 2019 13854.63 12877.98 14831.29 12360.97 15348.29 ## Sep 2019 13854.63 12785.20 14924.07 12219.07 15490.20 ## Oct 2019 13854.63 12699.84 15009.43 12088.53 15620.74 ## Nov 2019 13854.63 12620.37 15088.90 11967.00 15742.27 ## Dec 2019 13854.63 12545.72 15163.55 11852.83 15856.44 ## Jan 2020 13854.63 12475.11 15234.16 11744.83 15964.44 O valor de \\(\\alpha\\) encontrado ffoi de 0,9999, praticamente um modelo ingênuo. 5.2 Linear de Holt Holt criou uma extensão ao método de suavização simples que permite prever dados com tendência que possui dois parâmetros \\(\\alpha\\) e \\(\\beta\\). Matematicamente, temos: \\(\\hat{y}_{t+h}=l_t + hT_t\\) \\(l_t = \\alpha y_t + (1 - \\alpha)(l_{t-1} + T_{t-1})\\) \\(T_t = \\beta (l_t - l_{t-1}) + (1 - \\beta)T_{t-1}\\) Onde \\(T_t\\) corresponde a uma estimativa do componente de tendência e \\(l_t\\) uma estimativa do componente de nível da série no período \\(t\\). Assim como \\(\\alpha\\), o parâmetro \\(\\beta\\) também está definido no intervalo [0,1]. Recomenda-se que \\(l_0\\) e \\(T_0\\) sejam inicializados como \\(y_1\\) e \\(y_2 - y_1\\), respectivamente. No R, a função para aplicar o modelo linear de Holt é forecast::holt(). Os parâmetros podem ser impostos manualmente ou calculados automaticamente por otimização: mod1 &lt;- holt(energia, alpha = 0.6, beta = 0.4) mod2 &lt;- holt(energia) mod2$model ## Holt&#39;s method ## ## Call: ## holt(y = energia) ## ## Smoothing parameters: ## alpha = 0.9845 ## beta = 1e-04 ## ## Initial states: ## l = 5052.3993 ## b = 19.8743 ## ## sigma: 344.5037 ## ## AIC AICc BIC ## 8408.184 8408.313 8428.958 plot(mod1) lines(fitted(mod1), col = &quot;blue&quot;) lines(fitted(mod2), col = &quot;red&quot;) # calculando a qualidade de ajuste list(mod1, mod2) %&gt;% map(accuracy) ## [[1]] ## ME RMSE MAE MPE MAPE MASE ## Training set -0.3120712 423.4344 313.9757 -0.01667693 3.026252 0.5703046 ## ACF1 ## Training set 0.233788 ## ## [[2]] ## ME RMSE MAE MPE MAPE MASE ## Training set -1.307393 343.0377 258.776 -0.05088298 2.566114 0.4700401 ## ACF1 ## Training set 0.001255276 5.3 Holt-winter aditivo e multiplicativo Uma evolução do modelo linear de Holt foi criado por Holt e Winter para possibilitar a modelagem de séries temporais por suavização exponencial que também possuam um componente sazonal. O método de Holt-Winters possui três equações para calcular os componentes \\(l_t\\) de nível, \\(T_t\\) de tendência e \\(s_t\\) de sazonalidade, com os parâmetros \\(\\alpha\\), \\(\\beta\\) e \\(\\gamma\\). Esse método possui duas variações, que dependem da natureza do componente sazonal. O método aditivo é preferido quand as variações sazonais são razoavelmente constantes por toda a série, enquanto o multiplicativo pode ser usado quando as variações sazonais são proporcionais à mudança do nível da série. A formulação matemática completa, um pouco mais complexa que o modelo linear de Holt, pode ser encontrada aqui. No R, este método é implementado pela função forecast::hw(): # vamos testar tanto o metodo aditivo quanto o multiplicativo para a serie de exemplo ajuste_ad &lt;- hw(energia, seasonal = &quot;additive&quot;) ajuste_mult &lt;- hw(energia, seasonal = &quot;multiplicative&quot;) plot(energia) lines(fitted(ajuste_ad), col = &quot;blue&quot;) lines(fitted(ajuste_mult), col = &quot;red&quot;) # calculando a qualidade de ajuste list(ajuste_ad, ajuste_mult) %&gt;% map(accuracy) ## [[1]] ## ME RMSE MAE MPE MAPE MASE ## Training set -17.92829 266.2171 195.4297 -0.2371204 2.03023 0.354978 ## ACF1 ## Training set 0.03126608 ## ## [[2]] ## ME RMSE MAE MPE MAPE MASE ## Training set -5.999514 263.2171 194.9375 -0.1027663 1.978821 0.354084 ## ACF1 ## Training set 0.01280095 5.4 Seleção automática do melhor modelo de suavização exponencial Além dos apresentados neste capítulo, existem muito mais variações de métodos de suavização exponencial. São 15 no total, que são: Felizmente, o pacote forecast traz uma função que automatiza internamente a seleção do melhor método de previsão, através da função ets(): # ajustando um modelo modelo.ets &lt;- ets(energia) # verificando o output summary(modelo.ets) ## ETS(A,N,A) ## ## Call: ## ets(y = energia) ## ## Smoothing parameters: ## alpha = 0.8344 ## gamma = 0.1103 ## ## Initial states: ## l = 5705.8554 ## s = -122.337 194.4542 169.5002 267.6885 309.4918 27.2327 ## 37.4583 50.5964 68.238 -243.8595 -385.6998 -372.7637 ## ## sigma: 269.556 ## ## AIC AICc BIC ## 8186.889 8187.944 8249.212 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set 20.455 265.5196 197.8673 0.177949 2.042775 0.3594056 ## ACF1 ## Training set 0.0222034 Para a série temporal de exemplo, a função retornou um modelo ETS(A, N, A). A primeira letra se refere ao componente de erro e pode ser A (aditivo) ou M (multiplicativo), a segunda ao componente de tendência e pode ser N (não possui), A (aditivo), Ad (aditivo amortecido), M (multiplicativo) ou Md (multiplicativo amortecido) e a terceira ao componente de sazonalidade, que pode ser N, A ou M. Ou seja, o algoritmo da função detectou que a série de exemplo possui componente de erro aditivo, não possui tendência e a sazonalidade é aditiva. O ajuste do modelo, graficamente, é: plot(energia) lines(fitted(modelo.ets), col = &quot;red&quot;) "],
["arima.html", "Capítulo 6 Modelos ARIMA 6.1 Estacionariedade, diferenciação e autocorrelação 6.2 Modelos autoregressivos 6.3 Modelos de média móvel 6.4 Modelos ARIMA 6.5 Modelos SARIMA", " Capítulo 6 Modelos ARIMA Modelos ARIMA são outra classe de modelos populares em forecasting. A diferença entre modelos de suavização exponencial e os ARIMA é que os primeiros são baseados em descrever a tendência e a sazonalidade na série, enquanto os segundos se baseam em autocorrelações presentes nos dados. Para este capítulo, continuaremos usando a série temporal do consumo de energia pela indústria no Brasil. library(forecast) library(tidyverse) energia &lt;- readRDS(&quot;data/ts_energia.Rda&quot;) Antes de explicar o que é ARIMA, precisamos introduzir conceitos básicos como estacionariedade. 6.1 Estacionariedade, diferenciação e autocorrelação Uma série temporal é dita estacionária se suas propriedades (média, variância, etc.) não dependem do tempo da observação. Portanto, séries que apresentam tendência ou sazonalidade não são estacionárias. Por outro lado, uma série composta por valores gerados aleatoriamente (ex. pela função rnorm) são estacionárias, visto que a “aparência” da série é basicamente a mesma para qualquer período \\(t\\). A série abaixo é estacionária? data(&quot;lynx&quot;) head(lynx) ## Time Series: ## Start = 1821 ## End = 1826 ## Frequency = 1 ## [1] 269 321 585 871 1475 2821 autoplot(lynx) Por curiosidade, linces são isto: Aparentemente, a série apresenta ciclos ou sazonalidade, certo? Vamos ver seus componentes por dentro: lynx %&gt;% decompose() %&gt;% autoplot() ## Error in decompose(.): time series has no or less than 2 periods lynx %&gt;% stl(s.window = &quot;periodic&quot;) %&gt;% autoplot() ## Error in stl(., s.window = &quot;periodic&quot;): series is not periodic or has less than two periods Por que a função retorna um erro? Acontece que esta série não possui sazonalidade. Os algoritmos de decomposição não foram capazes de detectar períodos em que padrões se repetem, visto que os ciclos, além de possuírem níveis não constantes, acontecem em diferentes períodos, tornando-os imprevisíveis. Voltando a nossa série de exemplo. Ela é estacionária? energia %&gt;% autoplot() Claramente, ela não é. Contudo, existe um método muito simples para a tornar estacionária, que é a diferenciação. Ele se baseia nada mais em calcular a diferença absoluta (ou percentual) entre uma observação e a outra. O intervalo entre as observações pode ser escolhido pelo usuário: head(energia, 10) ## Jan Feb Mar Apr May Jun Jul Aug Sep Oct ## 1980 4806 4808 4833 4901 5009 5162 5149 5432 5369 5391 head(diff(energia), 10) ## Feb Mar Apr May Jun Jul Aug Sep Oct Nov ## 1980 2 25 68 108 153 -13 283 -63 22 114 head(diff(energia, 2), 10) ## Mar Apr May Jun Jul Aug Sep Oct Nov Dec ## 1980 27 93 176 261 140 270 220 -41 136 -270 # plotando as series par(mfrow=c(3,1)) plot(energia, main = &quot;Série original&quot;, xlab = &quot;&quot;, ylab = &quot;&quot;) plot(diff(energia), main = &quot;Série diferenciada&quot;, xlab = &quot;&quot;, ylab = &quot;&quot;) # plotando uma serie aleatoria: plot(rnorm(length(energia)), type = &quot;l&quot;, main = &quot;Dados aleatórios&quot;, xlab = &quot;&quot;, ylab = &quot;&quot;) Vemos pelo gráfico que a série diferenciada se aproxima muito de dados gerados aleatoriamente, comprovando que o método da diferenciação tornou a série estacionária. Uma outra maneira de analisar a estacionariedade de uma série é pelo conceito de autocorrelação, que é uma medida do relacionamento linear entre os valores dentro de uma mesma série (como se fosse uma correlação interna). A autocorrelação depende do lag que se deseja analisar. Por exemplo, \\(r1\\) se refere à relação entre \\(y_t\\) e \\(y_{t-1}\\). A melhor maneira de se analisar a autocorrelação de uma série é por meio de gráficos: lag.plot(energia, lags = 9) No gráfico de dispersão acima, vimos que em todos os 9 lags analisados, existe uma correlação forte entre as observações entre si. Numericamente, temos: Acf(energia, plot = FALSE)$acf %&gt;% as.vector() ## [1] 1.0000000 0.9895288 0.9793583 0.9701326 0.9616287 0.9539380 0.9469652 ## [8] 0.9401798 0.9345256 0.9296718 0.9265290 0.9244649 0.9207918 0.9112844 ## [15] 0.9016482 0.8932005 0.8856901 0.8792969 0.8726764 0.8664785 0.8610202 ## [22] 0.8551207 0.8509758 0.8480218 0.8431056 0.8330215 0.8226599 Outro gráfico muito útil para analisar a autocorrelação é o próprio gráfico de autocorrelação, também conhecido como correlograma: Acf(energia) A linha horizonal tracejada azul define o nível de significância mínimo. Isto é, se uma autocorrelação estiver acima dessa linha, ela é estatisticamente significativa. Contudo, a situação é diferente para a série diferenciada, como mostram os gráficos abaixo: lag.plot(diff(energia), lags = 9) Acf(diff(energia)) O fato de ainda haver três valores podem indicar duas coisas: Que a série diferenciada ainda não é estacionária; Que a série diferenciada é sim estacionária, pois esses lags com forte autocorrelação podem ser devidos a uma aleatoriedade. De fato, espera-se que, para uma série aleatória, 5% dos valores na ACF encontrem-se fora do intervalo \\(\\pm 2/ \\sqrt{T}\\). 6.2 Modelos autoregressivos A diferença entre modelos regressivos e autoregressivos é que os primeiros prevêem o valor de uma variável de interesse usando uma combinação linear (equação) das variáveis explanatórias. Já os segundos usam uma combinação linear de valores passados da própria variável. Matematicamente, um modelo autoregressivo é descrito como: \\(y_t = c + \\phi_1y_{t-1} + \\phi_2y_{t-2} + ... + \\phi_py_{t-p} + e_t\\) Onde \\(c\\) é uma constante e \\(e_t\\) é um erro aleatório (ruído branco). Esse tipo de modelo é chamado de modelo AR(p) e são normalmente restritos a séries estacionárias. No R, modelos autoregressivos podem ser ajustados por meio da função arima: # explicaremos o que é o argumento order da função abaixo daqui a pouco ar.p1 &lt;- energia %&gt;% diff() %&gt;% arima(order = c(1, 0, 0)) ar.p2 &lt;- energia %&gt;% diff() %&gt;% arima(order = c(2, 0, 0)) coefficients(ar.p1) %&gt;% round(4) ## ar1 intercept ## -0.0130 19.2715 coefficients(ar.p2) %&gt;% round(4) ## ar1 ar2 intercept ## -0.0140 -0.0822 19.2385 Portanto, as equações resultantes do ajuste de modelos autoregressivos de ordem 1 e 2 são, respectivamente: \\(y_t = 21.1135 - 0.0135y_{t-1} + e_t\\) \\(y_t = 20.9643 - 0.01435y_{t-1} - 0.0143y_{t-2} + e_t\\) 6.3 Modelos de média móvel Modelos de média móvel utilizam valores passados de erro de previsão de maneira semelhante a um modelo de regressão: \\(y_t = c + e_t + \\theta_1e_{t-1} + \\theta_2e_{t-2} + ... + \\theta_qe_{t-q}\\) Um modelo acima é chamado de modelo MA(q) e pode ser interpretado como um modelo onde \\(y_t\\) é uma média ponderada dos erros de previsão passados. 6.4 Modelos ARIMA A combinação entre os métodos de diferenciação e os modelos de autoregressão e média móvel resultam em um modelo ARIMA (AutoRegressive Integrated Moving Average model) não-sazonal, que pode ser descrito matematicamente como: \\(\\acute{y_t} = c + \\phi_1\\acute{y}_{t-1} + ... + \\phi_p\\acute{y}_{t-p} + \\theta_1 + \\theta_1e_{t-1} + ... + \\theta_qe_{t-q} + e_t\\) Onde \\(\\acute{y}_t\\) é a série diferenciada. A equação acima é o que descreve o modelo ARIMA(p, d, q), onde: \\(p\\) é a ordem do modelo autoregressivo; \\(d\\) é o grau de diferenciação; \\(q\\) é a ordem do modelo de média móvel. Como seria complicado selecionar valores apropriada para cada um desses três parâmetros, a função forecast::auto.arima() faz isso automaticamente: mod.arima &lt;- auto.arima(energia, seasonal = FALSE) summary(mod.arima) ## Series: energia ## ARIMA(1,1,2) with drift ## ## Coefficients: ## ar1 ma1 ma2 drift ## 0.6842 -0.7456 -0.1086 19.4967 ## s.e. 0.0798 0.0866 0.0525 7.2082 ## ## sigma^2 estimated as 113359: log likelihood=-3400 ## AIC=6810.01 AICc=6810.14 BIC=6830.77 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set 0.2500474 334.8969 253.1834 -0.02693067 2.5143 0.4598817 ## ACF1 ## Training set 0.003546764 O modelo resultante é um ARIMA(2, 1, 1), o que corresponde a uma combinação a uma série com um grau de diferenciação (p = 1) aplicada em um modelo AR(2) e em um MA(1). É possível saber o comportamento da previsão de um modelo ARIMA apenas baseado nos valores dos coeficientes c e d: Se \\(c = 0\\) e \\(d = 0\\), previsões em longo prazo serão iguais a zero; Se \\(c = 0\\) e \\(d = 1\\), serão iguais a uma constante maior que zero; Se \\(c \\neq 0\\) e \\(d = 2\\), seguirão uma linha reta; Se \\(c \\neq 0\\) e \\(d = 0\\), convergirão para a média da série; Se \\(c \\neq 0\\) e \\(d = 1\\), seguirão uma linha reta; Se \\(c \\neq 0\\) e \\(d = 2\\), seguirão uma tendência quadrática; No caso do nosso exemplo, vamos ver se isso se aplica: mod.arima %&gt;% forecast(h = 36) %&gt;% autoplot() Conforme esperado, as previsões seguem uma linha reta, o que, em palavras, indicam que a série crescerá indefinitivamente. Como ficaram as previsões de outras combinações ARIMA? Vamos fazer o teste: # criar funcao para extrair previsao de um modelo arima prever.arima &lt;- function(p = 0, d, q = 0, con) { # argumento c = binario TRUE ou FALSE # argumento d = 0, 1 ou 2 x &lt;- Arima(energia, order = c(p, d, q), include.constant = con, seasonal = c(0, 0, 0)) x &lt;- forecast(x) as.numeric(x$mean) } # plotar previsoes prever.arima(d = 1, con = FALSE) %&gt;% plot(type = &quot;l&quot;) prever.arima(d = 0, con = FALSE) %&gt;% lines(col = &quot;red&quot;) prever.arima(d = 2, con = FALSE) %&gt;% lines(col = &quot;orange&quot;) prever.arima(d = 0, con = TRUE) %&gt;% lines(col = &quot;green&quot;) prever.arima(d = 1, con = TRUE) %&gt;% lines(col = &quot;pink&quot;) prever.arima(d = 2, con = TRUE) %&gt;% lines(col = &quot;blue&quot;) 6.5 Modelos SARIMA Modelos ARIMA são capazes também de modelar séries que apresentam um componente sazonal, sendo descrito como: ARIMA \\((p, d, q)(P, D, Q)_m\\) Onde o primeiro parênteses se refere à parte não-sazonal do modelo e o segundo à parte sazonal. \\(m\\) corresponde ao número de períodos sazonais. Ajustar um modelo SARIMA é semelhante ao processo de ajustar um ARIMA: mod.sarima &lt;- auto.arima(energia, seasonal = TRUE) mod.sarima ## Series: energia ## ARIMA(1,0,1)(0,1,2)[12] with drift ## ## Coefficients: ## ar1 ma1 sma1 sma2 drift ## 0.9655 -0.1093 -0.6945 -0.1370 20.3127 ## s.e. 0.0137 0.0465 0.0470 0.0458 4.8901 ## ## sigma^2 estimated as 68706: log likelihood=-3211.86 ## AIC=6435.72 AICc=6435.9 BIC=6460.49 mod.sarima %&gt;% forecast(h = 36) %&gt;% autoplot() Para a série de análise, qual modelo possui o melhor ajuste: o sazonal ou o não-sazonal? # calculando a qualidade de ajuste: list(mod.arima, mod.sarima) %&gt;% map(accuracy) ## [[1]] ## ME RMSE MAE MPE MAPE MASE ## Training set 0.2500474 334.8969 253.1834 -0.02693067 2.5143 0.4598817 ## ACF1 ## Training set 0.003546764 ## ## [[2]] ## ME RMSE MAE MPE MAPE MASE ## Training set 1.518877 257.3437 187.2863 0.0006205425 1.888167 0.3401863 ## ACF1 ## Training set -0.002581607 # calculando a qualidade preditiva treino &lt;- window(energia, end = c(2015, 12)) teste &lt;- window(energia, start = c(2016, 1)) mod.arima2 &lt;- auto.arima(treino, seasonal = FALSE) %&gt;% forecast(teste) ## Warning in 1:h: numerical expression has 39 elements: only the first used mod.sarima2 &lt;- auto.arima(treino, seasonal = TRUE) %&gt;% forecast(teste) list(mod.arima2, mod.sarima2) %&gt;% map(forecast) %&gt;% map(accuracy, teste) ## [[1]] ## ME RMSE MAE MPE MAPE MASE ## Training set 0.290353 326.0823 246.5337 -0.02778075 2.491441 0.4303939 ## Test set 164.165281 367.2520 325.1233 1.12888967 2.343479 0.5675941 ## ACF1 Theil&#39;s U ## Training set -0.0981782 NA ## Test set 0.4006154 1.033457 ## ## [[2]] ## ME RMSE MAE MPE MAPE ## Training set 4.834388 279.3321 205.7491 0.04012374 2.137084 ## Test set 1544.035378 1710.4150 1555.9073 11.01891349 11.113601 ## MASE ACF1 Theil&#39;s U ## Training set 0.3591928 -0.002323165 NA ## Test set 2.7162735 0.850060508 5.025037 Apesar de o modelo ARIMA possuir o pior qualidade de ajuste, seu desempenho para prever valores futuros é superior ao SARIMA. "],
["outros.html", "Capítulo 7 Outros Métodos 7.1 Redes Neurais 7.2 Pacote mafs", " Capítulo 7 Outros Métodos # install.packages(c(&quot;fpp&quot;, &quot;vars&quot;)) library(fpp) library(forecast) library(tidyverse) library(vars) library(mafs) Forecasting é um assunto amplo demais para ser compreendido em algumas poucas horas. Existem dezenas de métodos de previsão diferentes, cada um apropriada a situações específicas. Além das técnicas clássicas apresentadas aqui, existem ainda algumas outras que vem ganhando destaque. 7.1 Redes Neurais Redes neurais artificiais são métodos de previsão baseados em modelos matemáticos do cérebro humano. Permitem relacionamentos não-lineares complexos entre a variável dependente e a independente. Uma rede neural pode ser interpretada como uma rede de neurônios organizados em camadas. Os preditores ou inputs formam a camada de baixo e as previsões ou outputs formam a camada de cima. As camadas intermediárias, que podem existir ou não, são chamadas de ocultas. Cada preditor tem um coeficiente associado a ele, chamado de peso. Inicialmente, os pesos atribuídos aos inputs são valores aleatórios que são atualizados a medida em que a rede neural utiliza um algoritmo de aprendizagem para minimizar uma função de custo do modelo, que corresponde a uma métrica de erro. A formulação matemática de uma rede neural é razoavelmente complexa. Contudo, ajustá-la em uma série temporal é bem simples: energia &lt;- readRDS(&quot;data/ts_energia.Rda&quot;) mod.rn &lt;- nnetar(energia) %&gt;% forecast(h = 36) autoplot(mod.rn) 7.2 Pacote mafs O pacote mafs é basicamente um atalho para o pacote forecast. Sua função principal é select_forecast(), que recebe uma série temporal como input, divide-a em séries de treino e teste, ajusta 18 modelos diferentes no conjunto de treino, mede sua acurácia em relação ao conjunto de teste, seleciona o melhor modelo de acordo com a métrica de erro escolhida pelo usuário e retorna os resultados dos modelos ajustados e os valores previstos para o futuro. Um exemplo de uso: system.time({ mod.mafs &lt;- select_forecast(energia, test_size = 24, horizon = 24, error = &quot;MAPE&quot;) }) ## Warning in mean.default(x, na.rm = TRUE): argument is not numeric or ## logical: returning NA ## Warning in trainingaccuracy(f, test, d, D): test elements must be within ## sample ## user system elapsed ## 104.212 39.878 91.081 A função select_forecast() retorna como output uma lista de três elementos: O resultado da acurácia dos modelos na série de teste; mod.mafs$df_models %&gt;% arrange(MAPE) %&gt;% knitr::kable() model ME RMSE MAE MPE MAPE MASE ACF1 best_model runtime_model tbats 37.529127 208.9966 154.3667 0.2495710 1.101182 0.2726785 0.3058238 tbats 5.844 bats 8.397109 206.3553 160.0462 0.0451775 1.148213 0.2827109 0.2801706 tbats 2.089 StructTS -65.694710 235.3721 163.7315 -0.4814760 1.180864 0.2892207 0.2224535 tbats 1.076 stlm_arima -55.927922 231.2390 178.6971 -0.4099147 1.285967 0.3156564 0.1845728 tbats 0.094 hybrid -138.913205 242.6880 179.7722 -1.0063123 1.293593 0.3175555 0.2127121 tbats 9.481 ets 157.249033 265.8208 222.2503 1.1101750 1.584445 0.3925902 0.2877032 tbats 2.084 stlm_ets 193.465478 300.4347 250.3780 1.3671693 1.785035 0.4422759 0.2721314 tbats 0.074 rwf_drift -122.184230 355.2741 270.4215 -0.9174526 1.950492 0.4776815 0.4760469 tbats 0.003 naive 132.916667 330.8344 281.5000 0.9003014 1.993695 0.4972509 0.4091301 tbats 0.003 rwf 132.916667 330.8344 281.5000 0.9003014 1.993695 0.4972509 0.4091301 tbats 0.003 thetaf -267.714726 349.1746 289.8854 -1.9143248 2.069838 0.5120632 0.3747142 tbats 0.020 snaive 300.333333 392.3578 341.5833 2.1211653 2.424632 0.6033840 0.3988863 tbats 0.002 croston 259.494479 398.9009 345.9204 1.8022156 2.439079 0.6110452 0.4091301 tbats 5.439 auto.arima -496.467178 593.7442 496.4672 -3.5474593 3.547459 0.8769760 0.5551156 tbats 4.217 nnetar -996.266813 1118.5003 996.2668 -7.1297376 7.129738 1.7598385 0.7258767 tbats 2.136 tslm -2097.396996 2108.3717 2097.3970 -14.9618287 14.961829 3.7049111 0.3339955 tbats 0.004 meanf 3475.189597 3488.3703 3475.1896 24.7152453 24.715245 6.1386892 0.4091301 tbats 0.001 A previsão gerada pelo melhor modelo (no caso, o auto.arima): mod.mafs$best_forecast %&gt;% autoplot() A comparação entre os valores da série de teste e da previsão resultante do modelo na série de treino: mod.mafs$df_comparison %&gt;% knitr::kable() time forecasted observed 2017-04-02 14031.10 14007 2017-05-02 14026.53 13598 2017-06-02 14025.90 13919 2017-07-02 14083.19 14082 2017-08-02 14305.20 14197 2017-09-01 14306.58 14146 2017-10-02 14202.73 14173 2017-11-01 14270.23 14316 2017-12-02 13838.47 14073 2018-01-01 13490.05 13597 2018-01-31 13616.93 13845 2018-03-03 13843.76 14023 2018-04-02 14031.10 14539 2018-05-03 14026.53 14048 2018-06-02 14025.90 13525 2018-07-03 14083.19 14170 2018-08-02 14305.20 14486 2018-09-02 14306.58 14419 2018-10-02 14202.73 14312 2018-11-01 14270.23 14498 2018-12-02 13838.47 14001 2019-01-01 13490.05 13575 2019-02-01 13616.93 13575 2019-03-03 13843.76 13858 "],
["clusterizacao.html", "Capítulo 8 Aplicações avançadas em séries temporais: Clusterização 8.1 Motivação 8.2 Introdução de técnicas avançadas em Séries Temporais 8.3 Clusterização de séries temporais 8.4 Demonstração", " Capítulo 8 Aplicações avançadas em séries temporais: Clusterização 8.1 Motivação É possível encontrar em diversas fontes, como em livros ou na Internet, ótimos conteúdos sobre Séries Temporais (um bom exemplo é o post no blog do IBPAD sobre algumas dessas referências). Contudo, muitas vezes esses materiais acabam sendo repetitivos, abordando basicamente os mesmos temas: sazonalidade, tendência, ARIMA, forecasting, etc. Isso dificulta ao praticante de séries temporais dar o próximo passo, isto é, avançar em seus estudos sobre o tema e ampliar seu conhecimento. Por isso, este post se destina a apresentar técnicas avançadas em Séries Temporais para você turbinar suas análises. 8.2 Introdução de técnicas avançadas em Séries Temporais O artigo Time-Series Data Mining, de Esling e Agon (2012), lista algumas técnicas de mineração de dados aplicadas a séries temporais, que são: Query by content: localizar padrões conhecidos em um banco de dados de séries temporais; Detecção de anomalias: detectar padrões incomuns em séries, como possíveis fraudes em transações financeiras; Descoberta de motifs: descobrir subsequências dentro de uma série temporal que se repetem em cadeias discretas; Classificação: distinguir séries temporais em rótulos ou classes conhecidas; Segmentação: Criar uma representação reduzida da série temporal; Previsão: estimar valores futuros baseado em valores passados da série; Clusterização: agrupar diferentes séries temporais em clusteres similares entre si. Todas essas técnicas podem ser implementadas no R graças a pacotes disponibilizados gratuitamente. Cada um desses tópicos renderia um (ou mais) post, portanto vou focar no momento apenas em clusterização. 8.3 Clusterização de séries temporais Clusterização é o processo de descobrir grupos, chamados de clusteres, em um conjunto de dados. O objetivo é determinar os clusteres mais homogêneos possíveis, isto é, os grupos em que os elementos sejam mais similares a elementos do mesmo cluster e mais diferentes de elementos de clusteres diferentes. Por exemplo, seria o mesmo que detectar, em uma loja de varejo, quais produtos são sazonais de verão ou de inverno baseado em suas séries de demanda. Uma excelente maneira de aprender mais sobre clusterização de séries temporais é lendo a documentação do pacote dtwclust, que implementa vários algoritmos conhecidos de clusterização. Neste post, iremos demonstrar como é possível encontrar grupos naturais analisando dados cambiais. Ou seja, a pergunta que se deseja responder é: Existem padrões naturais na variação cambial de moedas de países da América do Sul em relação ao dólar? 8.4 Demonstração 8.4.1 Obtenção dos dados Para esta análise, serão usados os seguintes pacotes: library(tidyverse) library(dtwclust) # clusterizacao de series temporais Abaixo, eu defino manualmente as moedas que serão usadas na análise: moedas &lt;- c(&quot;USD/ARS&quot;, &quot;USD/VEF&quot;, &quot;USD/BOB&quot;, &quot;USD/BRL&quot;, &quot;USD/CLP&quot;, &quot;USD/COP&quot;, &quot;USD/FKP&quot;, &quot;USD/PYG&quot;, &quot;USD/GYD&quot;, &quot;USD/PEN&quot;, &quot;USD/UYU&quot;, &quot;USD/SRD&quot;) Vamos então, de maneira iterativa para cada uma das moedas do vetor definido acima, obter a série temporal da cotação dos últimos 180 dias e salvar os resultados em uma lista: df_moedas &lt;- readr::read_csv(&quot;https://raw.githubusercontent.com/sillasgonzaga/curso_series_temporais/master/data/moedas.csv&quot;) 8.4.2 Transformação dos dados # olhando os dados obtidos df_moedas %&gt;% head() %&gt;% knitr::kable() data USD.ARS USD.VEF USD.BOB USD.BRL USD.CLP USD.COP USD.FKP USD.PYG USD.GYD USD.PEN USD.UYU USD.SRD 2018-12-05 37.51049 15701661 6.925374 3.858582 671.4947 3169.583 0.785610 5910.327 208.4773 3.381996 32.09173 7.456294 2018-12-06 37.62264 16219400 6.920337 3.884084 674.9416 3175.373 0.784250 5907.212 208.8974 3.377670 32.01777 7.456214 2018-12-07 37.55145 18811618 6.918612 3.887892 675.1803 3164.734 0.783959 5911.780 209.2960 3.371920 32.01822 7.456286 2018-12-08 37.37790 18807870 6.922675 3.907325 674.7750 3147.050 0.785472 5913.850 209.5450 3.366975 32.04850 7.456500 2018-12-09 37.37573 18808205 6.922675 3.907326 674.7784 3147.038 0.785546 5913.850 209.5450 3.366978 32.04850 7.454875 2018-12-10 37.48558 19432307 6.916634 3.911653 676.4515 3170.546 0.790034 5913.295 209.2420 3.370476 32.05107 7.448992 Veja que os dados possuem escalas distintas: existem moedas em que um dólar vale quase 3000 unidades dela. Para garantir que todas as moedas tenham o mesmo peso no algoritmo de clusterização, precisamos transformar os valores em uma mesma escala normalizada: # aplicar a funcao de normalizacao excluindo a coluna de data moedas_norm &lt;- scale(df_moedas[,-1]) moedas_norm %&gt;% head() %&gt;% knitr::kable() USD.ARS USD.VEF USD.BOB USD.BRL USD.CLP USD.COP USD.FKP USD.PYG USD.GYD USD.PEN USD.UYU USD.SRD -1.0282445 -1.607223 1.1267706 0.0766651 -0.2252835 -0.1745677 1.0479646 -1.623902 -1.6996649 2.311189 -1.206810 0.8911261 -0.9904478 -1.604254 0.3876272 0.3200150 0.0211982 -0.1001450 0.9343644 -1.648057 -0.6156920 2.128018 -1.277388 0.8733557 -1.0144396 -1.589390 0.1344959 0.3563524 0.0382677 -0.2368854 0.9100573 -1.612632 0.4127039 1.884551 -1.276965 0.8893491 -1.0729300 -1.589411 0.7307118 0.5417895 0.0092881 -0.4641859 1.0364375 -1.596585 1.0551915 1.675170 -1.248066 0.9368849 -1.0736604 -1.589409 0.7307118 0.5417991 0.0095336 -0.4643412 1.0426187 -1.596585 1.0551915 1.675297 -1.248066 0.5759236 -1.0366391 -1.585831 -0.1557613 0.5830890 0.1291779 -0.1621893 1.4174996 -1.600888 0.2733398 1.823409 -1.245610 -0.7308674 Com os dados normalizados, podemos então prosseguir com a análise. 8.4.3 Aplicação da clusterização Primeiramente, é possível encontrar clusteres naturais apenas no olho, sem a ajuda de nenhum algoritmo? Para responder a isso, vamos fazer um gráfico no ggplot2: moedas_norm %&gt;% as.data.frame() %&gt;% # transformar data frame em formato tidy (long) mutate(ind = row_number()) %&gt;% gather(moeda, cotacao_norm, -ind) %&gt;% ggplot(aes(x = ind, y = cotacao_norm)) + geom_point() + geom_smooth(method = &quot;loess&quot;, se = FALSE) + facet_wrap(~ moeda, scale =&quot;free_y&quot;) A maioria dos algoritmos de clusterização requer que a quantidade de clusteres seja definida pelo usuário. Olhando o gráfico acima, aparentemente, é possível dizer qeue existem três grupos naturais entre essas séries: as que apresentam tendência crescente, decrescente e as demais. Vamos então clusterizar a série em três grupos: modelo &lt;- tsclust(t(moedas_norm), k = 3, distance = &quot;dtw_lb&quot;, centroid = &quot;pam&quot;, seed = 123, trace = TRUE, control = partitional_control(pam.precompute = FALSE), args = tsclust_args(dist = list(window.size = 20L))) ## Iteration 1: Changes / Distsum = 12 / 685.6634 ## Iteration 2: Changes / Distsum = 1 / 617.6525 ## Iteration 3: Changes / Distsum = 1 / 614.9333 ## Iteration 4: Changes / Distsum = 0 / 614.9333 ## ## Elapsed time is 2.468 seconds. modelo ## partitional clustering with 3 clusters ## Using dtw_lb distance ## Using pam centroids ## ## Time required for analysis: ## user system elapsed ## 1.177 1.308 2.468 ## ## Cluster sizes with average intra-cluster distance: ## ## size av_dist ## 1 4 27.39003 ## 2 1 0.00000 ## 3 7 72.19618 plot(modelo) O que você achou do resultado dos clusteres? 8.4.4 E o Brasil? Em qual cluster o Real foi alocado? # descobrir cluster do Real (cl_br &lt;- (modelo@cluster[which(colnames(moedas_norm) == &quot;USD.BRL&quot;)])) ## [1] 3 # contar quantos paises ficaram no mesmo cluster do Brasil colnames(moedas_norm)[which(modelo@cluster == cl_br)] ## [1] &quot;USD.BRL&quot; &quot;USD.CLP&quot; &quot;USD.COP&quot; &quot;USD.FKP&quot; &quot;USD.GYD&quot; &quot;USD.PEN&quot; &quot;USD.SRD&quot; Vamos então destacar essas moedas em um gráfico só: # filtrar paises do mesmo cluster cl_br &lt;- as.data.frame(moedas_norm[, which(modelo@cluster == cl_br)]) cl_br %&gt;% mutate(indice = 1:n()) %&gt;% gather(moeda, cotacao_norm, -indice) %&gt;% ggplot(aes(x = indice, y = cotacao_norm)) + geom_line() + geom_smooth(se = FALSE) + facet_wrap( ~ moeda, scales = &quot;free&quot;) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; De fato, o comportamento entre as séries é relativamente parecido. "]
]
